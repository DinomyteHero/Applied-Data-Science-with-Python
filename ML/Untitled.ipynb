{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def blight_model():\n",
    "    # Load the data\n",
    "    train_df = pd.read_csv(\"readonly/train.csv\",encoding = 'ISO-8859-1')\n",
    "    test_df = pd.read_csv(\"readonly/test.csv\")\n",
    "    # Select the necessary data\n",
    "    train_df = train_df[(train_df['compliance'] == 0) | (train_df['compliance'] == 1)]\n",
    "    # Load the addresses and latlons data\n",
    "    address_df = pd.read_csv(\"readonly/addresses.csv\")\n",
    "    latlons_df = pd.read_csv(\"readonly/latlons.csv\")\n",
    "    \n",
    "    # Join the address data with the latlons\n",
    "    address_df = address_df.set_index('address').join(latlons_df.set_index('address'), how='left')\n",
    "    train_df = train_df.set_index('ticket_id').join(address_df.set_index('ticket_id'))\n",
    "    test_df =  test_df.set_index('ticket_id').join(address_df.set_index('ticket_id'))\n",
    "\n",
    "    # Filter null valued hearing date rows\n",
    "    train_df = train_df[~train_df['hearing_date'].isnull()]\n",
    "\n",
    "    # Remove  unnecessary Training Data columns\n",
    "    train_del = [\n",
    "            'balance_due',\n",
    "            'collection_status',\n",
    "            'compliance_detail',\n",
    "            'payment_amount',\n",
    "            'payment_date',\n",
    "            'payment_status'\n",
    "        ]\n",
    "\n",
    "    train_df.drop(train_del, axis=1, inplace=True)\n",
    "\n",
    "    # Remove String Data columns\n",
    "    string_del = ['violator_name', 'zip_code', 'country', 'city',\n",
    "            'inspector_name', 'violation_street_number', 'violation_street_name',\n",
    "            'violation_zip_code', 'violation_description',\n",
    "            'mailing_address_str_number', 'mailing_address_str_name',\n",
    "            'non_us_str_code', 'agency_name', 'state', 'disposition',\n",
    "            'ticket_issued_date', 'hearing_date', 'grafitti_status', 'violation_code'\n",
    "        ]\n",
    "    train_df.drop(string_del, axis=1, inplace=True)\n",
    "    test_df.drop(string_del, axis=1, inplace=True)\n",
    "\n",
    "    # Fill NA LatLon Values\n",
    "    train_df.lat.fillna(method='pad', inplace=True)\n",
    "    train_df.lon.fillna(method='pad', inplace=True)\n",
    "    test_df.lat.fillna(method='pad', inplace=True)\n",
    "    test_df.lon.fillna(method='pad', inplace=True)\n",
    "\n",
    "    # Get the dependant variable as an y-value and get rest of the values as an x-value\n",
    "    y_train = train_df.compliance\n",
    "    X_train = train_df.drop('compliance', axis=1)\n",
    "\n",
    "    # Nothing to do with test data\n",
    "    X_test = test_df\n",
    "    \n",
    "    # Use feature scaling to minimize computational time\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Build And Train Classifier Model\n",
    "    clf = MLPClassifier(hidden_layer_sizes = [100, 10],\n",
    "                        alpha=0.001,\n",
    "                        random_state = 0, \n",
    "                        solver='lbfgs', \n",
    "                        verbose=0)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_proba = clf.predict_proba(X_test_scaled)[:,1]\n",
    "    \n",
    "    # Integrate with reloaded test data\n",
    "    test_df = pd.read_csv('readonly/test.csv', encoding = \"ISO-8859-1\")\n",
    "    test_df['compliance'] = y_proba\n",
    "    test_df.set_index('ticket_id', inplace=True)\n",
    "    return test_df.compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def blight_model():\n",
    "    # Load the data\n",
    "    train_df = pd.read_csv(\"readonly/train.csv\",encoding = 'ISO-8859-1')\n",
    "    test_df = pd.read_csv(\"readonly/test.csv\")\n",
    "    # Select the necessary data\n",
    "    train_df = train_df[(train_df['compliance'] == 0) | (train_df['compliance'] == 1)]\n",
    "    # Drop any NA data for training\n",
    "    train_df = train_df.dropna(axis = 1,how  = 'all')\n",
    "    train_df = train_df.dropna(axis = 0,how  = 'all')\n",
    "    # Load the addresses and latlons data\n",
    "    address_df = pd.read_csv(\"readonly/addresses.csv\")\n",
    "    latlons_df = pd.read_csv(\"readonly/latlons.csv\")\n",
    "    \n",
    "    # Join the address data with the latlons\n",
    "    address_df = address_df.set_index('address').join(latlons_df.set_index('address'), how='left')\n",
    "    train_df = train_df.set_index('ticket_id').join(address_df.set_index('ticket_id'))\n",
    "    test_df =  test_df.set_index('ticket_id').join(address_df.set_index('ticket_id'))\n",
    "\n",
    "\n",
    "\n",
    "    # Remove  unnecessary Training Data columns\n",
    "    train_del = [\n",
    "            'balance_due',\n",
    "            'collection_status',\n",
    "            'compliance_detail',\n",
    "            'payment_amount',\n",
    "            'payment_date',\n",
    "            'payment_status'\n",
    "        ]\n",
    "\n",
    "    train_df.drop(train_del, axis=1, inplace=True)\n",
    "    test_df.drop('violation_zip_code',axis = 1,inplace = True)\n",
    "    # Remove String Data columns\n",
    "    string_del = ['violator_name',\n",
    "       'violation_street_number', 'violation_street_name',\n",
    "       'mailing_address_str_number', 'mailing_address_str_name', 'city',\n",
    "       'state', 'zip_code', 'country','non_us_str_code','violation_description',\n",
    "        'inspector_name','clean_up_cost','violation_code'\n",
    "        ]\n",
    "    train_df.drop(string_del, axis=1, inplace=True)\n",
    "    test_df.drop(string_del, axis=1, inplace=True)\n",
    "    \n",
    "    # Combine some Features\n",
    "    train_df['Total_amount_to_pay'] = train_df['fine_amount']+ train_df['admin_fee']+train_df['state_fee']+train_df['late_fee']-train_df['discount_amount']\n",
    "    list_drop = ['fine_amount','admin_fee','state_fee','late_fee','discount_amount']\n",
    "    train_df.drop(list_drop,axis = 1,inplace = True)\n",
    "    \n",
    "    test_df['Total_amount_to_pay'] = test_df['fine_amount']+ test_df['admin_fee']+test_df['state_fee']+test_df['late_fee']-test_df['discount_amount']\n",
    "    test_df.drop(list_drop,axis = 1,inplace = True)\n",
    "    \n",
    "    \n",
    "    train_df.dropna(subset = ['lat','lon','Total_amount_to_pay'],inplace = True) \n",
    "    test_df['lat'].fillna(test_df.lat.mean(),inplace = True)\n",
    "    test_df['lon'].fillna(test_df.lon.mean(),inplace = True)\n",
    "\n",
    "    \n",
    "    # Deal with time gap\n",
    "    from datetime import date\n",
    "    train_df['hearing_date'] = pd.to_datetime(train_df['hearing_date'])\n",
    "    train_df['ticket_issued_date'] = pd.to_datetime(train_df['ticket_issued_date'])\n",
    "    test_df['hearing_date'] = pd.to_datetime(test_df['hearing_date'])\n",
    "    test_df['ticket_issued_date'] = pd.to_datetime(test_df['ticket_issued_date'])\n",
    "    \n",
    "    train_df['hearing_date'].fillna(method = 'pad',inplace = True)\n",
    "    train_df['ticket_issued_date'].fillna(method = 'pad',inplace = True)\n",
    "    test_df['hearing_date'].fillna(method = 'pad',inplace = True)\n",
    "    test_df['ticket_issued_date'].fillna(method = 'pad',inplace = True)\n",
    "    \n",
    "    train_df['time_gap'] = train_df['hearing_date'].subtract(train_df['ticket_issued_date'])\n",
    "    train_df['time_gap'] = train_df['time_gap'].dt.days\n",
    "    train_df['time_gap'].fillna(73,inplace = True)\n",
    "    train_df.drop(['hearing_date','ticket_issued_date'],axis = 1,inplace = True)\n",
    "    \n",
    "    test_df['time_gap'] = test_df['hearing_date'].subtract(test_df['ticket_issued_date'])\n",
    "    test_df['time_gap'] = test_df['time_gap'].dt.days\n",
    "    test_df['time_gap'].fillna(73,inplace = True)\n",
    "    test_df.drop(['hearing_date','ticket_issued_date'],axis = 1,inplace = True)\n",
    "    \n",
    "    # Fill NA LatLon Values\n",
    "    train_df.dropna(subset = ['lat','lon','Total_amount_to_pay'],inplace = True) \n",
    "    test_df['lat'].fillna(test_df.lat.mean(),inplace = True)\n",
    "    test_df['lon'].fillna(test_df.lon.mean(),inplace = True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Get the dependant variable as an y-value and get rest of the values as an x-value \n",
    "    y_train = train_df['compliance']\n",
    "    X_train = train_df.drop('compliance',axis = 1)\n",
    "    X_test = test_df\n",
    "\n",
    "    \n",
    "\n",
    "    train_features = X_train\n",
    "    train_features_set = set(train_features)\n",
    "    \n",
    "    for feature in set(train_features):\n",
    "        if feature not in test_df:\n",
    "            train_features_set.remove(feature)\n",
    "    train_features = list(train_features_set)\n",
    "    \n",
    "    X_train = X_train[train_features]\n",
    "    X_test =  X_test[train_features]\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    reg = RandomForestRegressor(max_depth = 6,random_state=0).fit(X_train, y_train)\n",
    "    ypred = reg.predict(X_test)\n",
    "\n",
    "    \n",
    "    # Integrate with reloaded test data\n",
    "    test_df1 = pd.read_csv('readonly/test.csv', encoding = \"ISO-8859-1\")\n",
    "    test_df1['compliance'] = ypred\n",
    "    test_df1.set_index('ticket_id', inplace=True)\n",
    "    return test_df1.compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_df['hearing_date'] = pd.to_datetime(train_df['hearing_date'])\n",
    "    train_df['ticket_issued_date'] = pd.to_datetime(train_df['ticket_issued_date'])\n",
    "    test_df['hearing_date'] = pd.to_datetime(test_df['hearing_date'])\n",
    "    test_df['ticket_issued_date'] = pd.to_datetime(test_df['ticket_issued_date'])\n",
    "    \n",
    "    train_df['hearing_date'].fillna(method = 'pad',inplace = True)\n",
    "    train_df['ticket_issued_date'].fillna(method = 'pad',inplace = True)\n",
    "    test_df['hearing_date'].fillna(method = 'pad',inplace = True)\n",
    "    test_df['ticket_issued_date'].fillna(method = 'pad',inplace = True)\n",
    "    \n",
    "    train_df['time_gap'] = train_df['hearing_date'].subtract(train_df['ticket_issued_date'])\n",
    "    train_df['time_gap'] = train_df['time_gap'].dt.days\n",
    "    train_df['time_gap'].fillna(73,inplace = True)\n",
    "    train_df.drop(['hearing_date','ticket_issued_date'],axis = 1,inplace = True)\n",
    "    \n",
    "    test_df['time_gap'] = test_df['hearing_date'].subtract(test_df['ticket_issued_date'])\n",
    "    test_df['time_gap'] = test_df['time_gap'].dt.days\n",
    "    test_df['time_gap'].fillna(73,inplace = True)\n",
    "    test_df.drop(['hearing_date','ticket_issued_date'],axis = 1,inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
