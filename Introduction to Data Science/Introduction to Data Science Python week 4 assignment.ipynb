{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "def nfl_correlation(): \n",
    "    cities = pd.read_html(\"wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "    cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"},\n",
    "                  inplace=True)\n",
    "    cities['NFL'] = cities['NFL'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "    \n",
    "    team = cities['NFL'].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"窶能",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','')\n",
    "    \n",
    "    df=pd.read_csv(\"nfl.csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'[\\*]',\"\")\n",
    "    df['team'] = df['team'].str.replace(r'\\(\\d*\\)',\"\")\n",
    "    df['team'] = df['team'].str.replace(r'[\\xa0]',\"\")\n",
    "    df = df[['team','W-L%']]\n",
    "    df.rename(columns = {\"W-L%\" : \"W/L%\"}, inplace=True)\n",
    "    \n",
    "    dropList=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        row=df.iloc[i]\n",
    "        if row['team']==row['W/L%']:\n",
    "            dropList.append(i)\n",
    "    df=df.drop(dropList)\n",
    "\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','')\n",
    "    df['team'] = df['team'].str.replace('+','')\n",
    "    df = df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "\n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from _df in the same order as cities[\"Metropolitan area\"]   \n",
    "    \n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q4: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 29, \"Q4: There should be 29 teams being analysed for NFL\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004282141436393022"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfl_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nba_correlation():\n",
    "    cities = pd.read_html(\"wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "    cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"},\n",
    "                  inplace=True)\n",
    "    cities['NFL'] = cities['NBA'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "    team = cities[\"NBA\"].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"窶能",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','')\n",
    "\n",
    "    df=pd.read_csv(\"nba.csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'[\\*]',\"\")\n",
    "    df['team'] = df['team'].str.replace(r'\\(\\d*\\)',\"\")\n",
    "    df['team'] = df['team'].str.replace(r'[\\xa0]',\"\")\n",
    "    df = df[['team','W/L%']]\n",
    "    df['team']=df['team'].str.replace('\\ Sox','Sox')\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','')\n",
    "    df = df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "\n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from _df in the same order as cities[\"Metropolitan area\"]   \n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q2: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q2: There should be 28 teams being analysed for NBA\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1763635064218294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlb_correlation(): \n",
    "    cities = pd.read_html(\"wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "    cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"},\n",
    "              inplace=True)\n",
    "    cities['MLB'] = cities['MLB'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "    team = cities['MLB'].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"窶能",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('\\ Sox','Sox')\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','')\n",
    "\n",
    "    df=pd.read_csv(\"mlb.csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'[\\*]',\"\")\n",
    "    df['team'] = df['team'].str.replace(r'\\(\\d*\\)',\"\")\n",
    "    df['team'] = df['team'].str.replace(r'[\\xa0]',\"\")\n",
    "    df = df[['team','W-L%']]\n",
    "    df.rename(columns={\"W-L%\": \"W/L%\"},inplace=True)\n",
    "    df['team']=df['team'].str.replace('\\ Sox','Sox')\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','')\n",
    "    df = df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "    \n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from _df in the same order as cities[\"Metropolitan area\"]   \n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q3: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 26, \"Q3: There should be 26 teams being analysed for MLB\"\n",
    "    \n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15003737475409495"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def nhl_correlation(): \n",
    "    cities = pd.read_html(\"wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "    cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"},\n",
    "              inplace=True)\n",
    "    cities['NHL'] = cities['NHL'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "    team = cities['NHL'].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"窶能",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','')\n",
    "\n",
    "    df=pd.read_csv(\"nhl.csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'\\*',\"\")\n",
    "    df = df[['team','W','L']]\n",
    "\n",
    "    dropList=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        row=df.iloc[i]\n",
    "        if row['team']==row['W'] and row['L']==row['W']:\n",
    "            dropList.append(i)\n",
    "    df=df.drop(dropList)\n",
    "    \n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','')\n",
    "    df = df.astype({'team': str,'W': int, 'L': int})\n",
    "    df['W/L%'] = df['W']/(df['W']+df['L'])\n",
    "\n",
    "    df['team']=df['team'].str.replace('\\ Sox','Sox')\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','')\n",
    "    df = df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "    \n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from _df in the same order as cities[\"Metropolitan area\"]   \n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q3: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 26, \"Q3: There should be 26 teams being analysed for MLB\"\n",
    "    \n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def nhl_correlation():\n",
    "\n",
    "    cities = pd.read_html(\"wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "    cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"},\n",
    "                  inplace=True)\n",
    "    cities['NHL'] = cities['NHL'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "    \n",
    "    team = cities[\"NHL\"].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"窶能",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','')\n",
    "    \n",
    "    df=pd.read_csv(\"nhl.csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'\\*',\"\")\n",
    "    df = df[['team','W','L']]\n",
    "\n",
    "    dropList=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        row=df.iloc[i]\n",
    "        if row['team']==row['W'] and row['L']==row['W']:\n",
    "            dropList.append(i)\n",
    "    df=df.drop(dropList)\n",
    "\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','')\n",
    "#     _df['team'] = _df['team'].str.replace('.','')\n",
    "    df = df.astype({'team': str,'W': int, 'L': int})\n",
    "    df['W/L%'] = df['W']/(df['W']+ df['L'])\n",
    "    \n",
    "    merge=pd.merge(team,df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "    \n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from _df in the same order as cities[\"Metropolitan area\"]   \n",
    "\n",
    "    assert len(population_by_region) == len(\n",
    "        win_loss_by_region), \"Q1: Your lists must be the same length\"\n",
    "    assert len(population_by_region\n",
    "               ) == 28, \"Q1: There should be 28 teams being analysed for NHL\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012486162921209895"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhl_correlation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
